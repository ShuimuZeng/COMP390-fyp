{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6731175,
          "sourceType": "datasetVersion",
          "datasetId": 3877067
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:15.290604Z",
          "iopub.execute_input": "2023-10-19T09:42:15.290863Z",
          "iopub.status.idle": "2023-10-19T09:42:25.517845Z",
          "shell.execute_reply.started": "2023-10-19T09:42:15.290841Z",
          "shell.execute_reply": "2023-10-19T09:42:25.517057Z"
        },
        "trusted": true,
        "id": "1_s_HxS0V0i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxUA5VNKWPRI",
        "outputId": "97ee3e86-be7d-469b-b289-e626d4389c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'Sonnets.txt'\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "# print(raw_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:28.494777Z",
          "iopub.execute_input": "2023-10-19T09:42:28.495683Z",
          "iopub.status.idle": "2023-10-19T09:42:28.513485Z",
          "shell.execute_reply.started": "2023-10-19T09:42:28.495645Z",
          "shell.execute_reply": "2023-10-19T09:42:28.512768Z"
        },
        "trusted": true,
        "id": "MIyOtu4jV0jB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sonnets = raw_text.split('\\n\\n')\n",
        "sonnet_lens = [len(sonnet) for sonnet in sonnets]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:29.32698Z",
          "iopub.execute_input": "2023-10-19T09:42:29.327307Z",
          "iopub.status.idle": "2023-10-19T09:42:29.33157Z",
          "shell.execute_reply.started": "2023-10-19T09:42:29.327283Z",
          "shell.execute_reply": "2023-10-19T09:42:29.330844Z"
        },
        "trusted": true,
        "id": "PcZfkB7AV0jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sonnets\n",
        "# len(sonnet_lens)"
      ],
      "metadata": {
        "id": "mv9duI2DWyT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c,i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i,c) for i, c in enumerate(chars))\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(n_chars)\n",
        "print(n_vocab)\n",
        "print(char_to_int)\n",
        "print(int_to_char)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:31.231513Z",
          "iopub.execute_input": "2023-10-19T09:42:31.231827Z",
          "iopub.status.idle": "2023-10-19T09:42:31.237913Z",
          "shell.execute_reply.started": "2023-10-19T09:42:31.231803Z",
          "shell.execute_reply": "2023-10-19T09:42:31.236954Z"
        },
        "trusted": true,
        "id": "Al4H6m7AV0jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(n_chars, n_vocab)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:31.844885Z",
          "iopub.execute_input": "2023-10-19T09:42:31.845544Z",
          "iopub.status.idle": "2023-10-19T09:42:31.850125Z",
          "shell.execute_reply.started": "2023-10-19T09:42:31.845512Z",
          "shell.execute_reply": "2023-10-19T09:42:31.849034Z"
        },
        "trusted": true,
        "id": "qhSnq2Z8V0jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# string = 'abcd'\n",
        "# string[0:2]"
      ],
      "metadata": {
        "id": "9F2y9yABabPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3 #the step indicates how many characters to skip every time like from -> om which means to skip two charaters\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, n_chars-maxlen, step):\n",
        "    sentences.append(raw_text[i:i+maxlen])\n",
        "    next_chars.append(raw_text[i+maxlen])\n",
        "print(len(sentences)) # no of sequences\n",
        "print(len(next_chars)) # no of next charater of every senquence\n",
        "print(n_chars-maxlen)\n",
        "print(sentences)\n",
        "print(next_chars)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:33.927918Z",
          "iopub.execute_input": "2023-10-19T09:42:33.928513Z",
          "iopub.status.idle": "2023-10-19T09:42:33.95287Z",
          "shell.execute_reply.started": "2023-10-19T09:42:33.92848Z",
          "shell.execute_reply": "2023-10-19T09:42:33.951814Z"
        },
        "trusted": true,
        "id": "LxZhQpnFV0jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(sentences[:2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:43.658336Z",
          "iopub.execute_input": "2023-10-19T09:42:43.658674Z",
          "iopub.status.idle": "2023-10-19T09:42:43.663618Z",
          "shell.execute_reply.started": "2023-10-19T09:42:43.658648Z",
          "shell.execute_reply": "2023-10-19T09:42:43.662504Z"
        },
        "trusted": true,
        "id": "CRlWB9HcV0jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UdgXfRgQ0fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i,sentence in enumerate(sentences[:2]):\n",
        "#   print(\"Value of i\")\n",
        "#   print(i)\n",
        "#   print(\"value of sentence\")\n",
        "#   print(sentence)\n",
        "#   for t, char in enumerate(sentence):\n",
        "#     print(\"value of every t\")\n",
        "#     print(t)\n",
        "#     print(\"value of every char\")\n",
        "#     print(char)\n"
      ],
      "metadata": {
        "id": "lsbVpDiVSXGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorization\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
        "# print(x.shape)\n",
        "# print(y.shape)\n",
        "for i,sentence in enumerate(sentences):\n",
        "    # i is the index of every sentence in the sentences list,\n",
        "    #snetence is every sentence in the sentences list\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i,t,char_to_int[char]] = 1\n",
        "        #the x represents: i index of every sentence , t index of every character, char_to_int[char]\n",
        "        # is the corresponding value for every character in the sentence\n",
        "    y[i,char_to_int[next_chars[i]]] = 1\n",
        "    # i is explained, char_to_int[next_chars[i]] is the value of next character given the current sentence"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T09:42:44.604468Z",
          "iopub.execute_input": "2023-10-19T09:42:44.604803Z",
          "iopub.status.idle": "2023-10-19T09:42:45.016319Z",
          "shell.execute_reply.started": "2023-10-19T09:42:44.604774Z",
          "shell.execute_reply": "2023-10-19T09:42:45.015597Z"
        },
        "trusted": true,
        "id": "TPDnGd0SV0jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "LVrHtoC6M89g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0c26c7-8359-4306-d153-9d7da374e92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32044, 40, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:03:33.08583Z",
          "iopub.execute_input": "2023-10-19T10:03:33.086183Z",
          "iopub.status.idle": "2023-10-19T10:03:33.333854Z",
          "shell.execute_reply.started": "2023-10-19T10:03:33.086154Z",
          "shell.execute_reply": "2023-10-19T10:03:33.332984Z"
        },
        "trusted": true,
        "id": "hwl7l2LvV0jF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0d71a3-eecb-440b-b743-d88e706222b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               86528     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 40)                5160      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91688 (358.16 KB)\n",
            "Trainable params: 91688 (358.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.Sequential([\n",
        "#  keras.layers.GRU(128, return_sequences=True, input_shape=(maxlen, len(chars)),\n",
        "#  dropout=0.2, recurrent_dropout=0.2),\n",
        "#  keras.layers.GRU(128, return_sequences=False,\n",
        "#  dropout=0.2, recurrent_dropout=0.2),\n",
        "#  keras.layers.Dense(n_vocab,\n",
        "#  activation=\"softmax\")\n",
        "# ])\n",
        "\n",
        "# model.summary()\n",
        "# model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
        "# #history = model.fit(dataset, epochs=20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:03:35.365595Z",
          "iopub.execute_input": "2023-10-19T10:03:35.366413Z",
          "iopub.status.idle": "2023-10-19T10:03:35.369979Z",
          "shell.execute_reply.started": "2023-10-19T10:03:35.366382Z",
          "shell.execute_reply": "2023-10-19T10:03:35.369171Z"
        },
        "trusted": true,
        "id": "rVAEcRHmV0jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:03:36.261797Z",
          "iopub.execute_input": "2023-10-19T10:03:36.262718Z",
          "iopub.status.idle": "2023-10-19T10:03:36.268043Z",
          "shell.execute_reply.started": "2023-10-19T10:03:36.262682Z",
          "shell.execute_reply": "2023-10-19T10:03:36.267198Z"
        },
        "trusted": true,
        "id": "OXVNecNKV0jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(x[0])"
      ],
      "metadata": {
        "id": "LyEdmwZiVrkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=50)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:03:36.833023Z",
          "iopub.execute_input": "2023-10-19T10:03:36.833368Z",
          "iopub.status.idle": "2023-10-19T10:04:31.827767Z",
          "shell.execute_reply.started": "2023-10-19T10:03:36.833342Z",
          "shell.execute_reply": "2023-10-19T10:04:31.82712Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y73s9jZoV0jG",
        "outputId": "4c49b1f8-3828-4fe8-8c4c-4f395689ae7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "251/251 [==============================] - 27s 100ms/step - loss: 2.4598\n",
            "Epoch 2/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 1.9829\n",
            "Epoch 3/50\n",
            "251/251 [==============================] - 26s 103ms/step - loss: 1.8079\n",
            "Epoch 4/50\n",
            "251/251 [==============================] - 26s 102ms/step - loss: 1.6863\n",
            "Epoch 5/50\n",
            "251/251 [==============================] - 24s 97ms/step - loss: 1.5941\n",
            "Epoch 6/50\n",
            "251/251 [==============================] - 24s 96ms/step - loss: 1.5086\n",
            "Epoch 7/50\n",
            "251/251 [==============================] - 24s 96ms/step - loss: 1.4279\n",
            "Epoch 8/50\n",
            "251/251 [==============================] - 27s 106ms/step - loss: 1.3545\n",
            "Epoch 9/50\n",
            "251/251 [==============================] - 27s 106ms/step - loss: 1.2868\n",
            "Epoch 10/50\n",
            "251/251 [==============================] - 29s 115ms/step - loss: 1.2266\n",
            "Epoch 11/50\n",
            "251/251 [==============================] - 26s 102ms/step - loss: 1.1783\n",
            "Epoch 12/50\n",
            "251/251 [==============================] - 26s 102ms/step - loss: 1.1397\n",
            "Epoch 13/50\n",
            "251/251 [==============================] - 25s 99ms/step - loss: 1.1070\n",
            "Epoch 14/50\n",
            "251/251 [==============================] - 26s 104ms/step - loss: 1.0725\n",
            "Epoch 15/50\n",
            "251/251 [==============================] - 26s 103ms/step - loss: 1.0538\n",
            "Epoch 16/50\n",
            "251/251 [==============================] - 28s 111ms/step - loss: 1.0266\n",
            "Epoch 17/50\n",
            "251/251 [==============================] - 25s 99ms/step - loss: 1.0118\n",
            "Epoch 18/50\n",
            "251/251 [==============================] - 25s 99ms/step - loss: 0.9979\n",
            "Epoch 19/50\n",
            "251/251 [==============================] - 26s 103ms/step - loss: 0.9733\n",
            "Epoch 20/50\n",
            "251/251 [==============================] - 27s 109ms/step - loss: 0.9567\n",
            "Epoch 21/50\n",
            "251/251 [==============================] - 26s 104ms/step - loss: 0.9370\n",
            "Epoch 22/50\n",
            "251/251 [==============================] - 27s 108ms/step - loss: 0.9283\n",
            "Epoch 23/50\n",
            "251/251 [==============================] - 25s 101ms/step - loss: 0.9101\n",
            "Epoch 24/50\n",
            "251/251 [==============================] - 25s 100ms/step - loss: 0.8997\n",
            "Epoch 25/50\n",
            "251/251 [==============================] - 26s 104ms/step - loss: 0.8963\n",
            "Epoch 26/50\n",
            "251/251 [==============================] - 28s 111ms/step - loss: 0.8778\n",
            "Epoch 27/50\n",
            "251/251 [==============================] - 27s 107ms/step - loss: 0.8707\n",
            "Epoch 28/50\n",
            "251/251 [==============================] - 26s 103ms/step - loss: 0.8558\n",
            "Epoch 29/50\n",
            "251/251 [==============================] - 24s 98ms/step - loss: 0.8429\n",
            "Epoch 30/50\n",
            "251/251 [==============================] - 24s 96ms/step - loss: 0.8343\n",
            "Epoch 31/50\n",
            "251/251 [==============================] - 26s 102ms/step - loss: 0.8221\n",
            "Epoch 32/50\n",
            "251/251 [==============================] - 24s 95ms/step - loss: 0.8086\n",
            "Epoch 33/50\n",
            "251/251 [==============================] - 24s 97ms/step - loss: 0.7973\n",
            "Epoch 34/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.7905\n",
            "Epoch 35/50\n",
            "251/251 [==============================] - 26s 102ms/step - loss: 0.7797\n",
            "Epoch 36/50\n",
            "251/251 [==============================] - 26s 102ms/step - loss: 0.7642\n",
            "Epoch 37/50\n",
            "251/251 [==============================] - 24s 97ms/step - loss: 0.7566\n",
            "Epoch 38/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.7511\n",
            "Epoch 39/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.7460\n",
            "Epoch 40/50\n",
            "251/251 [==============================] - 24s 97ms/step - loss: 0.7365\n",
            "Epoch 41/50\n",
            "251/251 [==============================] - 24s 97ms/step - loss: 0.7310\n",
            "Epoch 42/50\n",
            "251/251 [==============================] - 27s 106ms/step - loss: 0.7168\n",
            "Epoch 43/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.7082\n",
            "Epoch 44/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.7042\n",
            "Epoch 45/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.6966\n",
            "Epoch 46/50\n",
            "251/251 [==============================] - 25s 98ms/step - loss: 0.6910\n",
            "Epoch 47/50\n",
            "251/251 [==============================] - 26s 104ms/step - loss: 0.6811\n",
            "Epoch 48/50\n",
            "251/251 [==============================] - 26s 104ms/step - loss: 0.6788\n",
            "Epoch 49/50\n",
            "251/251 [==============================] - 25s 99ms/step - loss: 0.6677\n",
            "Epoch 50/50\n",
            "251/251 [==============================] - 25s 99ms/step - loss: 0.6583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"./models/model_sp.h5\")"
      ],
      "metadata": {
        "id": "eE_hPv9oeNzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('model_sp.h5')"
      ],
      "metadata": {
        "id": "6ypf9mo8kg_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:04:31.82925Z",
          "iopub.execute_input": "2023-10-19T10:04:31.829499Z",
          "iopub.status.idle": "2023-10-19T10:04:31.834299Z",
          "shell.execute_reply.started": "2023-10-19T10:04:31.829478Z",
          "shell.execute_reply": "2023-10-19T10:04:31.833533Z"
        },
        "trusted": true,
        "id": "kgv5XmuHV0jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sonnet(temp, ok_sonnet):\n",
        "    ''' Given a temperature, generate a new sonnet '''\n",
        "    #start_idx = np.random.randint(0, len(raw_text) - maxlen - 1)\n",
        "    #new_sonnet = raw_text[start_idx:start_idx + maxlen]\n",
        "    ok_sonnet += \" why hath you been summoned at this bequet hour to mine chambers\"\n",
        "    new_sonnet = ok_sonnet[:maxlen]\n",
        "    for i in range(600):\n",
        "        # Vectorize generated text\n",
        "        sampled = np.zeros((1, maxlen, len(chars)))\n",
        "        for j, char in enumerate(new_sonnet):\n",
        "            sampled[0, j, char_to_int[char]] = 1.\n",
        "\n",
        "        # Predict next character\n",
        "        preds = model.predict(sampled, verbose=0)[0]\n",
        "        pred_idx = sample(preds, temperature=temp)\n",
        "        next_char = chars[pred_idx]\n",
        "\n",
        "        # Append predicted character to seed text\n",
        "        new_sonnet += next_char\n",
        "        new_sonnet = new_sonnet[1:]\n",
        "\n",
        "        # Print to console\n",
        "        print(next_char, end = '')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:06:07.243057Z",
          "iopub.execute_input": "2023-10-19T10:06:07.243341Z",
          "iopub.status.idle": "2023-10-19T10:06:07.249193Z",
          "shell.execute_reply.started": "2023-10-19T10:06:07.243318Z",
          "shell.execute_reply": "2023-10-19T10:06:07.248334Z"
        },
        "trusted": true,
        "id": "PKEf8SFuV0jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ok_sonnet = \" why hath you been summoned at this bequet hour to mine chambers\"\n",
        "new_sonnet = ok_sonnet[:maxlen]\n",
        "sampled = np.zeros((1, maxlen, len(chars)))"
      ],
      "metadata": {
        "id": "eH1RufD-Ftgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for j, char in enumerate(new_sonnet):\n",
        "#     sampled[0, j, char_to_int[char]] = 1.\n",
        "# print(sampled)"
      ],
      "metadata": {
        "id": "3FIH0e8JGkUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sonnet(0.36, 'from')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:06:23.374301Z",
          "iopub.execute_input": "2023-10-19T10:06:23.37459Z",
          "iopub.status.idle": "2023-10-19T10:06:50.332898Z",
          "shell.execute_reply.started": "2023-10-19T10:06:23.374569Z",
          "shell.execute_reply": "2023-10-19T10:06:50.332058Z"
        },
        "trusted": true,
        "id": "OhxLe_q8V0jH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52691aa6-496b-4a71-a2c9-2f4b0638ef7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mime.\n",
            "\n",
            "lxxxviii\n",
            "\n",
            "loo you love thee, of you are you troul love hild,\n",
            "that mine is toon to hold thy praise.\n",
            "\n",
            "lxx\n",
            "\n",
            "the sicpering with as truth bring woodd,\n",
            "when my bod the excest, and i evernce approve sheet word,\n",
            "thy youthere his grace which thoughts all will.\n",
            "\n",
            "xxv\n",
            "\n",
            "then lof your some i love that so reep wound:\n",
            "thy had my love should parts of thy dear with withit\n",
            "det but you some glory thy dear tike,\n",
            "though i made be be tume doth find wow,\n",
            "or those varts thy poor doth with submery.\n",
            "\n",
            "lxx\n",
            "\n",
            "then some from her have thy sweet live younds\n",
            "for if thou dart which the surmâ€™dess an ellight\n",
            "and you love th"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('char_to_int.pkl','wb') as f:\n",
        "    pickle.dump(char_to_int, f)\n",
        "\n",
        "with open('int_to_char.pkl', 'wb') as f:\n",
        "    pickle.dump(int_to_char, f)\n",
        "\n",
        "with open('shakespeare.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "with open('shakespeare_chars.pkl','wb') as f:\n",
        "    pickle.dump(chars, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-19T10:11:19.681054Z",
          "iopub.execute_input": "2023-10-19T10:11:19.681884Z",
          "iopub.status.idle": "2023-10-19T10:11:19.722674Z",
          "shell.execute_reply.started": "2023-10-19T10:11:19.681855Z",
          "shell.execute_reply": "2023-10-19T10:11:19.721826Z"
        },
        "trusted": true,
        "id": "WZS9IdiWV0jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymnnRaEvV0jI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}